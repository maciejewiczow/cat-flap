{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73713bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from random import randint\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from glob import glob\n",
    "import os\n",
    "from itertools import groupby\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "156c0d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "batch_size = 32\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c77315e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = randint(0, 2**32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "466a3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"datasets/processed_binary_split_manual\"\n",
    "baseWeightsSavePath = \"weights/best_binary_split_manual.keras\"\n",
    "baseFinetunedSavePath = \"weights/best_finetuned_binary_split_manual.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ff4bf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4814227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Session:\n",
    "    id: str\n",
    "    class_name: str\n",
    "    image_paths: list[str]\n",
    "    session_name: str\n",
    "    label: int\n",
    "\n",
    "class_names = ['close', 'open']\n",
    "\n",
    "sessions = [\n",
    "    Session(\n",
    "        id=f\"{class_name}_{session_name}\",\n",
    "        class_name=class_name,\n",
    "        image_paths=list(image_paths),\n",
    "        session_name=session_name,\n",
    "        label=class_names.index(class_name),\n",
    "    )\n",
    "    for (_, __, class_name, session_name), image_paths in groupby(\n",
    "        glob(f\"{dataDir}/**/*.jpg\", recursive=True),\n",
    "        lambda path: tuple(os.path.normpath(path).split(\"\\\\\")[:4]),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "session_ids = [s.id for s in sessions]\n",
    "labels = [s.label for s in sessions]\n",
    "\n",
    "# First split: training vs temporary (val+test)\n",
    "# We use stratification to maintain class balance\n",
    "train_sessions, temp_sessions = train_test_split(\n",
    "    session_ids,\n",
    "    test_size=(val_size + test_size),\n",
    "    stratify=labels,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "# Second split: val vs test from temporary sessions\n",
    "# Adjust split size: we want val_size/(val_size+test_size) of temp\n",
    "val_test_ratio = val_size / (val_size + test_size)\n",
    "val_sessions, test_sessions = train_test_split(\n",
    "    temp_sessions,\n",
    "    test_size=(1 - val_test_ratio),  # This gives us the right proportion\n",
    "    stratify=[label for sid, label in zip(session_ids, labels) if sid in temp_sessions],\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "train_data = [s for s in sessions if s.id in train_sessions]\n",
    "val_data = [s for s in sessions if s.id in val_sessions]\n",
    "test_data = [s for s in sessions if s.id in test_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b59592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create TensorFlow datasets\n",
    "def create_dataset_from_sessions(session_data: list[Session], augment=False, shuffle=False):\n",
    "    \"\"\"Convert session data to a tf.data.Dataset.\"\"\"\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Flatten the session structure into individual images\n",
    "    for session in session_data:\n",
    "        all_image_paths.extend(session.image_paths)\n",
    "        all_labels.extend([session.label] * len(session.image_paths))\n",
    "\n",
    "    # Create TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((all_image_paths, all_labels))\n",
    "\n",
    "    # Shuffle if needed (do this before mapping for better performance)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(all_image_paths), seed=seed)\n",
    "\n",
    "    # Load and preprocess images\n",
    "    def load_and_preprocess_image(path, label):\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, IMG_SIZE)\n",
    "        image = keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    # Apply augmentation only to training set\n",
    "    if augment:\n",
    "        augmentation_layers = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "                keras.layers.RandomTranslation(0.2, 0.2, fill_mode=\"nearest\"),\n",
    "                keras.layers.RandomRotation(0.2),\n",
    "                keras.layers.RandomZoom(0.1),\n",
    "                keras.layers.RandomBrightness(0.1),\n",
    "                keras.layers.RandomContrast(0.1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        def augment_image(image, label):\n",
    "            image = augmentation_layers(image, training=True)\n",
    "            return image, label\n",
    "\n",
    "        dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # Batch and prefetch for performance\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset, len(all_image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d053b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_count = create_dataset_from_sessions(\n",
    "    train_data, augment=True, shuffle=True\n",
    ")\n",
    "val_ds, val_count = create_dataset_from_sessions(val_data)\n",
    "test_ds, test_count = create_dataset_from_sessions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f6b39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback_base = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=baseWeightsSavePath,\n",
    "    monitor=\"val_accuracy\",  # You can use 'val_loss' for less overfitting\n",
    "    save_best_only=True,  # Critical: only save if validation improves\n",
    "    save_weights_only=False,  # Save entire model (architecture + weights)\n",
    "    mode=\"max\",  # 'max' for accuracy, 'min' for loss\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "checkpoint_callback_finetune = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=baseFinetunedSavePath,\n",
    "    monitor=\"val_accuracy\",  # You can use 'val_loss' for less overfitting\n",
    "    save_best_only=True,  # Critical: only save if validation improves\n",
    "    save_weights_only=False,  # Save entire model (architecture + weights)\n",
    "    mode=\"max\",  # 'max' for accuracy, 'min' for loss\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Callback 2: Early stopping to prevent overfitting\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,  # Stop after 5 epochs without improvement\n",
    "    restore_best_weights=True,  # Keep the best weights when stopping\n",
    ")\n",
    "\n",
    "# Callback 3: Reduce learning rate when plateauing\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,  # Reduce learning rate by half\n",
    "    patience=3,  # Wait 3 epochs\n",
    "    min_lr=1e-7,  # Minimum learning rate\n",
    ")\n",
    "\n",
    "callbacks = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ac815dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_close_count = sum(1 for s in test_data if s.class_name == 'close')\n",
    "train_open_count = sum(1 for s in test_data if s.class_name == 'open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c087b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = train_count\n",
    "close_weight = total / (2 * train_close_count)\n",
    "open_weight = total / (2 * train_open_count)\n",
    "class_weight = {0: close_weight, 1: open_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18042f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.MobileNetV2(\n",
    "    input_shape=IMG_SIZE + (3,), include_top=False, weights=\"imagenet\"\n",
    ")\n",
    "# Freeze the base model initially\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e2380bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        base_model,\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de635a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=30,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint_callback_base, *callbacks],\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b05cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(baseWeightsSavePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cb88959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 449ms/step - accuracy: 0.8462 - loss: 0.5606\n",
      "Validation Accuracy: 84.62%\n"
     ]
    }
   ],
   "source": [
    "validation_loss, validation_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Validation Accuracy: {validation_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4f12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phase 2: Fine-tuning last 40 layers...\n",
      "Epoch 15/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732ms/step - accuracy: 0.5776 - loss: 0.6851\n",
      "Epoch 15: val_accuracy improved from None to 0.65722, saving model to weights/best_finetuned_binary.keras\n",
      "\n",
      "Epoch 15: finished saving model to weights/best_finetuned_binary.keras\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 914ms/step - accuracy: 0.5761 - loss: 0.6839 - val_accuracy: 0.6572 - val_loss: 0.6280 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735ms/step - accuracy: 0.5619 - loss: 0.6879\n",
      "Epoch 16: val_accuracy did not improve from 0.65722\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 876ms/step - accuracy: 0.5669 - loss: 0.6850 - val_accuracy: 0.6544 - val_loss: 0.6265 - learning_rate: 1.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772ms/step - accuracy: 0.5357 - loss: 0.6925\n",
      "Epoch 17: val_accuracy did not improve from 0.65722\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 916ms/step - accuracy: 0.5499 - loss: 0.6899 - val_accuracy: 0.6459 - val_loss: 0.6269 - learning_rate: 1.0000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - accuracy: 0.5520 - loss: 0.6846\n",
      "Epoch 18: val_accuracy did not improve from 0.65722\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 874ms/step - accuracy: 0.5662 - loss: 0.6779 - val_accuracy: 0.6544 - val_loss: 0.6265 - learning_rate: 5.0000e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743ms/step - accuracy: 0.5692 - loss: 0.6806\n",
      "Epoch 19: val_accuracy did not improve from 0.65722\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 882ms/step - accuracy: 0.5789 - loss: 0.6786 - val_accuracy: 0.6516 - val_loss: 0.6279 - learning_rate: 5.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762ms/step - accuracy: 0.5761 - loss: 0.6765\n",
      "Epoch 20: val_accuracy did not improve from 0.65722\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 897ms/step - accuracy: 0.5754 - loss: 0.6762 - val_accuracy: 0.6516 - val_loss: 0.6282 - learning_rate: 5.0000e-06\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "fine_tune = 40\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    layer.trainable = i >= len(base_model.layers) - fine_tune\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # Much smaller LR # pyright: ignore[reportArgumentType]\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "print(f\"\\nPhase 2: Fine-tuning last {fine_tune} layers...\")\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    epochs=30,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint_callback_finetune, *callbacks],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d01e91",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.load_weights(baseFinetunedSavePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6b104e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in test_ds:\n",
    "    y_true.append(label_batch.numpy())\n",
    "\n",
    "    pred = model.predict(image_batch)\n",
    "\n",
    "    indices = np.argmax(pred, axis=-1)\n",
    "\n",
    "    res = np.zeros_like(pred)\n",
    "\n",
    "    np.put_along_axis(res, indices[:, None], 1, axis=-1)\n",
    "\n",
    "    y_pred.append(res)\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = np.concat(y_true, axis=0)\n",
    "predicted_labels = np.concat(y_pred, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c55f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823f4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "220c2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       close       0.00      0.00      0.00       107\n",
      "        open       0.68      1.00      0.81       231\n",
      "\n",
      "    accuracy                           0.68       338\n",
      "   macro avg       0.34      0.50      0.41       338\n",
      "weighted avg       0.47      0.68      0.55       338\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projekty\\misc\\cat-flap\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Projekty\\misc\\cat-flap\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\Projekty\\misc\\cat-flap\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x274b8a0dbd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(correct_labels, predicted_labels,target_names=class_names))\n",
    "\n",
    "cmat = confusion_matrix(\n",
    "    correct_labels,\n",
    "    predicted_labels,\n",
    "    labels=[0, 1],\n",
    ")\n",
    "\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cmat,\n",
    "    display_labels=class_names\n",
    ").plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat-flap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
